---
title: "Welcome to all my code"
execute:
  echo: true
  eval: false
---

## Data Cleaning

In this section, we will perform data cleaning and prepare various datasets for analysis.

```{python}
import os
import numpy as np
import torch
import pandas as pd
import nltk
import re
from nltk.tokenize import sent_tokenize
nltk.download('punkt')
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS

```

Extract names of all data files, store in `files` array, and extract names of all presidents and store in `president_names` array.

```{python}
#| echo: true

folder_path = 'data'
files = os.listdir(folder_path)
files = [file for file in files if os.path.isfile(os.path.join(folder_path, file))]

for file in files[:3]:
    print(file)

president_names = []

# Define a regular expression pattern to match the president's name
pattern = r'_(.*?)\.txt'

for file in files:
    match = re.search(pattern, file)
    if match:
        president_name = match.group(1)
        # remove prefix and if not there its fine already
        president_name = president_name.replace('post_elections_', '').replace('pre_elections_', '')
        president_names.append(president_name)


```

Make dataset of presidents (column 1) and sentences (column 2).

```{python}
#| echo: true
df = pd.DataFrame(columns=['completion', 'prompt'])

# read in file and skip the first two lines
for file_index in range(len(files)):

    file_path = f'data/{files[file_index]}'  
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()[2:]

    # Combine the lines into a single text
    text = ' '.join(lines)

    # tokenize the text into sentences using NLTK
    sentences = sent_tokenize(text) # remove "\n" 
    # remove "\n"
    cleaned_sentences = [sentence.replace('\n', '') for sentence in sentences]

    current_president = president_names[file_index]
    dftemp = pd.DataFrame({'completion': current_president,  'prompt': cleaned_sentences})
    df = pd.concat([df,dftemp], axis=0)

# remove stopwords function
def remove_stopwords(sentence):
    words = sentence.split()
    filtered_words = [word for word in words if word.lower() not in ENGLISH_STOP_WORDS]
    return " ".join(filtered_words)

df['prompt'] = df['prompt'].apply(remove_stopwords)

df.reset_index(drop=True, inplace=True)

df.to_csv("data.csv")
df["completion"].to_csv("y.csv")
```

### Bag of Words 

```{python}
import pandas as pd
import re
from sklearn.feature_extraction.text import CountVectorizer

def bow_x():
    # Read the data once
    data = pd.read_csv("data.csv")
    
    # Extract relevant columns
    text_data = data['prompt']
    y = data['completion']
    
    # Initialize a CountVectorizer for BOW representation
    vectorizer = CountVectorizer(lowercase=True, token_pattern=r"(?u)\b\w+\b")
    
    # Fit and transform the text data
    X = vectorizer.fit_transform(text_data)
    
    # Create a DataFrame from the BOW representation
    bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())
    
    return bow_df

# function to return names of presidents
def bow_y():
  data = pd.read_csv("data.csv")
  y = data['completion']
  return(y)

```

### Term Frequency - Inverse Document Frequency

```{python}
# Imports
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
```

```{python}

def idf():
    df = pd.read_csv("data.csv").iloc[:,1:]
    sentences = df['prompt'].tolist()

    # Create a TfidfVectorizer
    tfidf_vectorizer = TfidfVectorizer()

    # Fit and transform the sentences to compute TF-IDF values
    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)

    # Create a new dataframe with TF-IDF values
    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())
    return tfidf_df

```

## Word Embedding

```{python}

import pandas as pd
from sklearn.model_selection import train_test_split
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences

def embeddings_data_prep():
    data = pd.read_csv("data.csv").iloc[:, 1:]

    # Tokenization
    max_features = 1000
    tokenizer = Tokenizer(num_words=max_features)
    tokenizer.fit_on_texts(data['prompt'])
    sequences = tokenizer.texts_to_sequences(data['prompt'])

    # Filter out empty sequences and corresponding labels
    filtered_indices = [i for i, s in enumerate(sequences) if len(s) > 0]
    sequences = [sequences[i] for i in filtered_indices]
    y = data['completion'].iloc[filtered_indices].values

    # Splitting data into training, validation, and test sets
    x_train, x_temp, y_train, y_temp = train_test_split(sequences, y, test_size=0.3, random_state=42)
    x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)

    maxlen = 50
    x_train_pad = pad_sequences(x_train, maxlen=maxlen)
    x_val_pad = pad_sequences(x_val, maxlen=maxlen)
    x_test_pad = pad_sequences(x_test, maxlen=maxlen)

    return x_train_pad, x_val_pad, x_test_pad, y_train, y_val, y_test


#x_train_pad, x_val_pad, x_test_pad, y_train, y_val, y_test = embeddings_data_prep()
```

## Exploratory Data Analysis

Number of sentences per president.

```{python}
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS

data = pd.read_csv("data.csv").iloc[:,1:]
sentence_counts = data['completion'].value_counts()

plt.figure(figsize=(10, 6))
sns.barplot(x=sentence_counts.index, y=sentence_counts.values)
plt.xlabel('', fontsize=16)
plt.ylabel('Number of Sentences', fontsize=16)
ax.tick_params(axis='both', which='major', labelsize=14)  
plt.savefig('eda_plots/sentence_counts.png', bbox_inches='tight')
plt.show()

```

Sentence length plot.

```{python}
data['sentence_length'] = data['prompt'].apply(lambda x: len(x.split()))
average_sentence_length = data.groupby('completion')['sentence_length'].mean().reset_index()
desired_order = [4, 2, 3, 1, 0, 5]
average_sentence_length = average_sentence_length.loc[desired_order]
# Plot the barplot of average sentence lengths per president
plt.figure(figsize=(10, 6))
sns.barplot(x='completion', y='sentence_length', data=average_sentence_length)
plt.xlabel('', fontsize=16)
ax.tick_params(axis='both', which='major', labelsize=14)  
plt.ylabel('Average sentence length', fontsize=16)
plt.savefig('eda_plots/sentence_length.png', bbox_inches='tight')
plt.show()
```

Produce word cloud.

```{python}

presidents = data['completion'].unique()
for president in presidents:
    text = " ".join(data[data['completion'] == president]['prompt'])
    
    # Create a WordCloud object
    wordcloud = WordCloud(width=800, height=400, background_color='grey').generate(text)
    
    # Plot the word cloud
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    #plt.title(f'Word Cloud for President {president}')
    plt.axis('off')
    plt.show()
```

## Models

### Neural Network

```{python}
# Import required libraries
import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import sklearn
import pickle
#from bow import bow_x, bow_y

# Import necessary modules
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from math import sqrt
from sklearn.preprocessing import LabelEncoder


# Keras specific
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical 
from keras.models import Sequential
from keras.layers import Dense
from keras.regularizers import l2
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

x = bow_x()
y = bow_y()
def data_prep(x,y):
    X_train, X_temp, y_train, y_temp = train_test_split(x, y, test_size=0.3, random_state=42)
    # Split your data into training and validation sets
    X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)
    X_train = X_train.values
    X_val = X_val.values
    X_test = X_test.values

    label_encoder = LabelEncoder()

    # Fit and transform the labels to integer labels
    y_train_encoded = label_encoder.fit_transform(y_train)
    y_val_encoded = label_encoder.fit_transform(y_val)
    y_test_encoded = label_encoder.fit_transform(y_test)

    # Convert to one-hot encoded vector
    y_train = to_categorical(y_train_encoded)
    y_val = to_categorical(y_val_encoded)
    y_test = to_categorical(y_test_encoded)

    # dimensions
    inp_dim = X_test.shape[1]
    count_classes = y_test.shape[1]
    return {
        'X_train': X_train,
        'X_val': X_val,
        'X_test': X_test,
        'y_train': y_train,
        'y_val': y_val,
        'y_test': y_test,
        'inp_dim': inp_dim,
        'count_classes': count_classes
    }
data = data_prep(x,y)
X_train = data['X_train']
X_val = data['X_val']
X_test = data['X_test']
y_train = data['y_train']
y_val = data['y_val']
y_test= data['y_test']
inp_dim = data['inp_dim']
count_classes = data['count_classes']
num_epochs = 20

# function to train and test model with specific params
def create_custom_model(neurons_per_layer, l2_reg_value):
    # Create a Sequential model
    model = Sequential()
    neurons_per_layer = [500, 200]
    # Add the input layer with L2 regularization
    model.add(Dense(neurons_per_layer[0], activation='relu', input_dim=inp_dim, kernel_regularizer=l2(l2_reg_value)))

    # Add hidden layers with L2 regularization
    for num_neurons in neurons_per_layer[1:]:
        model.add(Dense(num_neurons, activation='relu', kernel_regularizer=l2(l2_reg_value)))

    # Add the output layer with L2 regularization
    model.add(Dense(count_classes, activation='softmax', kernel_regularizer=l2(l2_reg_value)))

    # Compile the model
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    # Train the model with validation data
    history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_val, y_val))

    # Evaluate the model on training and test data
    scores_train = model.evaluate(X_train, y_train, verbose=1)
    scores_test = model.evaluate(X_test, y_test, verbose=0)
    

    # print('Accuracy on training data: {:.2f}%\nError on training data: {:.2f}'.format(scores_train[1] * 100, (1 - scores_train[1]) * 100))
    # print('Accuracy on test data: {:.2f}%\nError on test data: {:.2f}'.format(scores_test[1] * 100, (1 - scores_test[1]) * 100))

    # Access validation scores from the history object
    val_loss = history.history['val_loss']
    val_accuracy = history.history['val_accuracy']

    y_pred = model.predict(X_test)
    y_pred_classes = np.argmax(y_pred, axis=1)  # Convert one-hot encoded predictions to class labels

    # Convert one-hot encoded ground truth labels to class labels
    y_true_classes = np.argmax(y_test, axis=1)

    # Calculate accuracy, precision, recall, and F1 score
    accuracy = accuracy_score(y_true_classes, y_pred_classes)
    precision = precision_score(y_true_classes, y_pred_classes, average=None)
    recall = recall_score(y_true_classes, y_pred_classes, average=None)
    f1 = f1_score(y_true_classes, y_pred_classes,
     average=None)

    # print('Accuracy on test data: {:.2f}%'.format(accuracy * 100))
    # print('Precision on test data: {:.2f}'.format(precision))
    # print('Recall on test data: {:.2f}'.format(recall))
    # print('F1 score on test data: {:.2f}'.format(f1))

    return {
        'val_loss': val_loss,
        'val_accuracy': val_accuracy,
        'train_loss': history.history['loss'],
        'train_accuracy': history.history['accuracy'],
        'test_loss': scores_test[0],
        'test_accuracy': scores_test[1],
        'precision': precision,
        'recall': recall,
        'f1_score': f1
        }

```



Create 3 model architectures, and implement L2 regularization on best performing one. First with BoW data.

```{python}

bow_results_2 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0)
bow_results_3 = create_custom_model(neurons_per_layer=[500,200,100], l2_reg_value=0)
bow_results_4 = create_custom_model(neurons_per_layer=[800,400,100,50], l2_reg_value=0)

# bow_results_2["test_accuracy"] #0.5952890515327454
# bow_results_3["test_accuracy"] #0.5852962136268616
# bow_results_4["test_accuracy"] #0.6038544178009033

```

Now regularize the 2 layer Neural Network, since the benefit is incremental, but much less compute needed.

```{python}
bow_results_2_001 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0.01)

bow_results_2_005 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0.05)

bow_results_2_01 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0.1)

bow_results_2_001["test_accuracy"] #0.5952890515327454
bow_results_2_005["test_accuracy"] #0.5852962136268616
bow_results_2_01["test_accuracy"] #0.6038544178009033

bow_results_2_0 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0)

```
```{python}
file_path = 'nn_res/bow_results_2_0.pkl'
with open(file_path, 'wb') as file:
    pickle.dump(bow_results_2_0, file)

```

Now do the same process but for TF-IDF dataset.

```{python}
#from tf_idf import idf
# import idf data
x = idf()
data = data_prep(x,y)
X_train = data['X_train']
X_val = data['X_val']
X_test = data['X_test']
y_train = data['y_train']
y_val = data['y_val']
y_test= data['y_test']
inp_dim = data['inp_dim']
count_classes = data['count_classes']

idf_results_2 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0)
idf_results_3 = create_custom_model(neurons_per_layer=[500,200,100], l2_reg_value=0)
idf_results_4 = create_custom_model(neurons_per_layer=[800,400,100,50], l2_reg_value=0)

idf_results_2["test_accuracy"] #0.600285530090332
idf_results_3["test_accuracy"] #0.599571704864502
idf_results_4["test_accuracy"] #0.5888651013374329


idf_results_2_001 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0.01)

idf_results_2_005 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0.05)

idf_results_2_01 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0.1)

# no reg is the best
idf_results_2_0 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0)


# idf_results_2_001["test_accuracy"] #0.600285530090332
# idf_results_2_005["test_accuracy"] #0.599571704864502
# idf_results_2_01["test_accuracy"] #0.5888651013374329
idf_results_2_0["test_accuracy"]

file_path = 'nn_res/idf_results_2_0.pkl'
with open(file_path, 'wb') as file:
    pickle.dump(idf_results_2_0, file)
```

And train networks for word embeddings.

```{python}
#from embedding import embeddings_data_prep

X_train, X_val, X_test, y_train, y_val, y_test = embeddings_data_prep()
# encode the y values
label_encoder = LabelEncoder()

# Fit and transform the labels to integer labels
y_train_encoded = label_encoder.fit_transform(y_train)
y_val_encoded = label_encoder.fit_transform(y_val)
y_test_encoded = label_encoder.fit_transform(y_test)

# Convert to one-hot encoded vector
y_train = to_categorical(y_train_encoded)
y_val = to_categorical(y_val_encoded)
y_test = to_categorical(y_test_encoded)

# dimensions
inp_dim = X_test.shape[1]
count_classes = y_test.shape[1]
```

```{python}
# train models
num_epochs = 100
embeds_results_2 = create_custom_model(neurons_per_layer=[40,10], l2_reg_value=0)
embeds_results_3 = create_custom_model(neurons_per_layer=[40,30,10], l2_reg_value=0)
embeds_results_4 = create_custom_model(neurons_per_layer=[40,30,20,10], l2_reg_value=0)

embeds_results_2["test_accuracy"] #0.2942446172237396
embeds_results_3["test_accuracy"] #0.2942446172237396
embeds_results_4["test_accuracy"] #0.3179856240749359

# now with reg

embeds_results_2_001 = create_custom_model(neurons_per_layer=[40,30,20,10], l2_reg_value=0.01)

embeds_results_2_005 = create_custom_model(neurons_per_layer=[40,30,20,10], l2_reg_value=0.05)

embeds_results_2_01 = create_custom_model(neurons_per_layer=[40,30,20,10], l2_reg_value=0.1)


embeds_results_2_001["test_accuracy"] #0.600285530090332
embeds_results_2_005["test_accuracy"] #0.599571704864502
embeds_results_2_01["test_accuracy"] #0.5888651013374329
num_epochs = 200
embeds_results_2_0 = create_custom_model(neurons_per_layer=[40,30,20,10], l2_reg_value=0)


file_path = 'nn_res/embed_results_2_0.pkl'
with open(file_path, 'wb') as file:
    pickle.dump(embeds_results_2_0, file)

```

PLOT MODEL INFORMATION.

```{python}
with open("nn_res/bow_results_2_0.pkl", 'rb') as file:
    bow_res = pickle.load(file)

with open("nn_res/idf_results_2_0.pkl", 'rb') as file:
    idf_res = pickle.load(file)

with open("nn_res/embed_results_2_0.pkl", 'rb') as file:
    embed_res = pickle.load(file)

bow_val = bow_res["val_accuracy"]
idf_val = idf_res["val_accuracy"]
embed_val = embed_res["val_accuracy"][::10]
x_bow = range(len(bow_val))
x_idf = range(len(idf_val))
x_embed = range(len(embed_val))
x_ticks = list(range(20))

fig, ax = plt.subplots()
ax.plot(x_bow, bow_val, label='BoW')#, marker='o')
ax.plot(x_idf, idf_val, label='IDF')#, marker='s')
ax.plot(x_embed, embed_val, label='Embeddings')#, marker='^')

# Set labels and title
ax.set_xlabel('Epochs')
ax.set_ylabel('Validation Accuracy')
ax.set_title('Validation Accuracy Comparison')
ax.legend()
ax.set_xticks(range(21))
#plt.grid(True)
#plt.savefig('nn_res/nn_val_acc.png', bbox_inches='tight')
plt.show()

```

### Boosted Tree

```{python}
import catboost as cb
import numpy as np
import pandas as pd
import seaborn as sns
import shap
import re
import pickle
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.metrics import r2_score
from sklearn.inspection import permutation_importance
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from catboost import CatBoostClassifier
import collections
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
# from bow import bow_x, bow_y
# from tf_idf import idf
# from embedding import embeddings_data_prep
```

First we do catboost on BoW data.

```{python}
# SPLIT INTO BAG OF WORDS FORMAT
x = bow_x()
y = bow_y()
# split data train,val,test
# Split the data into training (70%), validation (15%), and test (15%) sets
x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.3, random_state=42)

x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)

# BRING DATA: SPLIT INTO TRAIN, VALIDATION AND TEST
train_dataset = cb.Pool(x_train, y_train) 
val_dataset = cb.Pool(x_val, y_val) 
test_dataset = cb.Pool(x_test, y_test)
# CREATE CATBOOST MODEL
catboost_classifier = CatBoostClassifier()
#CREATE GRID OF PARAMETERS
grid = {'iterations': [10, 50, 80],
        'learning_rate': [0.03, 0.05],
        'depth': [4, 5, 6],
        'l2_leaf_reg': [0.2, 0.5]}
# Define the parameter grid
grid_search = GridSearchCV(estimator=catboost_classifier, param_grid=grid, cv=3, n_jobs=-1)

# Fit the grid search to your data
grid_search.fit(x_train, y_train)  # Replace X and y with your feature and label data
# Get the best parameters and estimator
# best: {'depth': 6, 'iterations': 80, 'l2_leaf_reg': 0.2, 'learning_rate': 0.05}
best_params = grid_search.best_params_
best_params['iterations'] = 4000
# best_estimator = grid_search.best_estimator_
# y_pred = best_estimator.predict(x_test)
clf = CatBoostClassifier(**best_params)
clf.fit(train_dataset, eval_set=val_dataset, plot=True)
bow_val_acc = clf.eval_metrics(val_dataset, metrics=["Accuracy"])

# Calculate accuracy
y_pred = clf.predict(test_dataset)
accuracy = accuracy_score(y_test, y_pred)

# Calculate precision
precision = precision_score(y_test, y_pred, average=None)
recall = recall_score(y_test, y_pred, average=None)
f1 = f1_score(y_test, y_pred, average=None)
confusion = confusion_matrix(y_test, y_pred)

performance_metrics = {
    "val_accuracy": bow_val_acc,
    "accuracy": accuracy,
    "precision": precision,
    "recall": recall,
    "f1": f1,
    "confusion_matrix": confusion
}
# save val acc
file_path = 'catboost_info/bow_res.pkl'
with open(file_path, 'wb') as file:
    pickle.dump(performance_metrics, file)


```


Now run catboost on IDF data.

```{python}
x = idf()
y = pd.read_csv("y.csv").iloc[:,1:]
# split data train,val,test
# Split the data into training (70%), validation (15%), and test (15%) sets
x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.3, random_state=42)

x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)

# BRING DATA: SPLIT INTO TRAIN, VALIDATION AND TEST
train_dataset = cb.Pool(x_train, y_train) 
val_dataset = cb.Pool(x_val, y_val) 
test_dataset = cb.Pool(x_test, y_test)
# CREATE CATBOOST MODEL
catboost_classifier = CatBoostClassifier()
# CREATE GRID OF PARAMETERS
grid = {'iterations': [80],
        'learning_rate': [0.03, 0.05],
        'depth': [4, 5, 6],
        'l2_leaf_reg': [0.2, 0.5]}
# Define the parameter grid
grid_search = GridSearchCV(estimator=catboost_classifier, param_grid=grid, cv=3, n_jobs=-1)
# Fit the grid search to your data
grid_search.fit(x_train, y_train)  # Replace X and y with your feature and label data

# Get the best parameters and estimator
best_params = grid_search.best_params_
best_params['iterations'] = 4000
# best_estimator = grid_search.best_estimator_
# y_pred = best_estimator.predict(x_test)
clf = CatBoostClassifier(**best_params)
clf.fit(train_dataset, eval_set=val_dataset, plot=True)
idf_val_acc = clf.eval_metrics(val_dataset, metrics=["Accuracy"])

# Calculate accuracy
y_pred = clf.predict(test_dataset)
accuracy = accuracy_score(y_test, y_pred)

# Calculate precision
precision = precision_score(y_test, y_pred, average=None)
recall = recall_score(y_test, y_pred, average=None)
f1 = f1_score(y_test, y_pred, average=None)
confusion = confusion_matrix(y_test, y_pred)

performance_metrics = {
    "val_accuracy": idf_val_acc,
    "accuracy": accuracy,
    "precision": precision,
    "recall": recall,
    "f1": f1,
    "confusion_matrix": confusion
}
# save val acc
file_path = 'catboost_info/idf_res.pkl'
with open(file_path, 'wb') as file:
    pickle.dump(performance_metrics, file)

```

Now we do catboost on word embeddings.

```{python}
# split data train,val,test
x_train, x_val, x_test, y_train, y_val, y_test = embeddings_data_prep()

# BRING DATA: SPLIT INTO TRAIN, VALIDATION AND TEST
train_dataset = cb.Pool(x_train, y_train) 
val_dataset = cb.Pool(x_val, y_val) 
test_dataset = cb.Pool(x_test, y_test)
# CREATE CATBOOST MODEL
catboost_classifier = CatBoostClassifier()
# CREATE GRID OF PARAMETERS
grid = {'iterations': [80],
        'learning_rate': [0.03, 0.05],
        'depth': [4, 5, 6],
        'l2_leaf_reg': [0.2, 0.5]}
# Define the parameter grid
grid_search = GridSearchCV(estimator=catboost_classifier, param_grid=grid, cv=3, n_jobs=-1)
# Fit the grid search to your data
grid_search.fit(x_train, y_train)  # Replace X and y with your feature and label data

#Get the best parameters and estimator
best_params = grid_search.best_params_
best_params['iterations'] = 4000
# best_estimator = grid_search.best_estimator_
# y_pred = best_estimator.predict(x_test)
clf = CatBoostClassifier(**best_params)
clf.fit(train_dataset, eval_set=val_dataset, plot=True)
embed_val_acc = clf.eval_metrics(val_dataset, metrics=["Accuracy"])

# Calculate accuracy
y_pred = clf.predict(test_dataset)
accuracy = accuracy_score(y_test, y_pred)

# Calculate precision
precision = precision_score(y_test, y_pred, average=None)
recall = recall_score(y_test, y_pred, average=None)
f1 = f1_score(y_test, y_pred, average=None)
confusion = confusion_matrix(y_test, y_pred)

performance_metrics = {
    "val_accuracy": embed_val_acc,
    "accuracy": accuracy,
    "precision": precision,
    "recall": recall,
    "f1": f1,
    "confusion_matrix": confusion
}
# save val acc
file_path = 'catboost_info/embed_res.pkl'
with open(file_path, 'wb') as file:
    pickle.dump(performance_metrics, file)
```


Plot validation accuracy.
```{python}
with open('catboost_info/bow_res.pkl', 'rb') as file:
    cbbow_res = pickle.load(file)

with open('catboost_info/idf_res.pkl', 'rb') as file:
    cbidf_res = pickle.load(file)

with open('catboost_info/embed_res.pkl', 'rb') as file:
    cbembed_res = pickle.load(file)


cbbow_val = bow_res["val_accuracy"]["Accuracy"]
cbidf_val = idf_res["val_accuracy"]["Accuracy"]
cbembed_val = embed_res["val_accuracy"]["Accuracy"]
cb_bow = range(4000)
cb_idf = range(3995)
cb_embed = range(130)


fig, ax = plt.subplots()

# Plot the validation values for each experiment
ax.plot(cb_bow, cbbow_val, label='BoW')#, marker='o')
ax.plot(cb_idf, cbidf_val, label='IDF')#, marker='s')
ax.plot(cb_embed, cbembed_val, label='Embeddings')#, marker='^')

# Set labels and title
ax.set_xlabel('Epochs')
ax.set_ylabel('Validation Accuracy')
#ax.set_title('Validation Accuracy Comparison')
ax.legend()
plt.grid(True)
plt.savefig('catboost_info/cb_val_acc.png')#, bbox_inches='tight')
plt.show()

```


### Naive Bayes

```{python}
from sklearn.model_selection import GridSearchCV
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

import numpy as np
from sklearn.metrics import classification_report

from sklearn.preprocessing import LabelEncoder
from keras.utils import to_categorical 
import numpy as np
import pandas as pd
# from bow import bow_x, bow_y
# from tf_idf import idf
# from embedding import embeddings_data_prep
```

NB model for BoW data first.
```{python}
x = bow_x()
y = bow_y()
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)
# Split your data into training and validation sets
X_train = X_train.values
X_test = X_test.values

label_encoder = LabelEncoder()

# Fit and transform the labels to integer labels
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.fit_transform(y_test)

# Convert to one-hot encoded vector
y_train = to_categorical(y_train_encoded)
y_test = to_categorical(y_test_encoded)
```

Make a function to train NB model on custom data.
```{python}

def naive_bayes(X_train, y_train, X_test, y_test):
    # Define a grid of hyperparameter values to search through
    param_grid = {'alpha': [0.001, 0.01, 0.1, 1.0]}
    # Create a Multinomial Naive Bayes classifier
    nb_classifier = MultinomialNB()
    # Perform a grid search to find the best hyperparameter ('alpha')
    grid_search = GridSearchCV(nb_classifier, param_grid, cv=5, scoring='accuracy')
    # Fit the grid search to the training data
    grid_search.fit(X_train, np.argmax(y_train, axis=1))
    # Get the best Naive Bayes classifier based on the grid search results
    best_nb_classifier = grid_search.best_estimator_
    # Make predictions on the test set using the best classifier
    y_pred_nb = best_nb_classifier.predict(X_test)
    # Extract the true labels from one-hot encoded 'y_test'
    y_true = np.argmax(y_test, axis=1)
    # Calculate the accuracy of the classifier on the test set
    accuracy = accuracy_score(y_true, y_pred_nb)
    # Store the results including accuracy, best alpha, and the best classifier
    results = {
        'accuracy': accuracy,
        'best_alpha': grid_search.best_params_['alpha'],
        'fitted_model': best_nb_classifier
    }
    # Create a DataFrame to store results for reporting
    results_df = pd.DataFrame([{
        'best_alpha': results['best_alpha'],
        'train_accuracy': accuracy_score(np.argmax(y_train, axis=1), best_nb_classifier.predict(X_train)),
        'test_accuracy': accuracy
    }])
    
    # Return the results, results DataFrame, and the best classifier
    return results, results_df, best_nb_classifier

opt = naive_bayes(X_test=X_test,X_train=X_train,y_test=y_test, y_train=y_train)

# train the best model and output
mod = MultinomialNB()
param = {'alpha': [1.0]}
grid = GridSearchCV(mod, param, cv=5, scoring='accuracy')
grid.fit(X_train, np.argmax(y_train, axis=1))
best_mod = grid.best_estimator_
y_pred = best_mod.predict(X_test)
y_true = np.argmax(y_test, axis=1)
report = classification_report(y_true, y_pred)


```

Now do it for TF-IDF data.

```{python}
x = idf()
y = bow_y()
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)
# Split your data into training and validation sets
X_train = X_train.values
X_test = X_test.values

label_encoder = LabelEncoder()

# Fit and transform the labels to integer labels
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.fit_transform(y_test)

# Convert to one-hot encoded vector
y_train = to_categorical(y_train_encoded)
y_test = to_categorical(y_test_encoded)

opt = naive_bayes(X_test=X_test,X_train=X_train,y_test=y_test, y_train=y_train)

# train the best model and output
mod = MultinomialNB()
param = {'alpha': [0.1]}
grid = GridSearchCV(mod, param, cv=5, scoring='accuracy')
grid.fit(X_train, np.argmax(y_train, axis=1))
best_mod = grid.best_estimator_
y_pred = best_mod.predict(X_test)
y_true = np.argmax(y_test, axis=1)
report = classification_report(y_true, y_pred)

```

Now train the NB model with embeddings.

```{python}
X_train, X_val, X_test, y_train, y_val, y_test = embeddings_data_prep()

X_test = np.concatenate((X_val, X_test), axis=0)
y_test = np.concatenate((y_val, y_test), axis=0)

# encode the y values
label_encoder = LabelEncoder()

# Fit and transform the labels to integer labels
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.fit_transform(y_test)

# Convert to one-hot encoded vector
y_train = to_categorical(y_train_encoded)
y_test = to_categorical(y_test_encoded)

opt = naive_bayes(X_test=X_test,X_train=X_train,y_test=y_test, y_train=y_train)

# train the best model and output
mod = MultinomialNB()
param = {'alpha': [10]}
grid = GridSearchCV(mod, param, cv=5, scoring='accuracy')
grid.fit(X_train, np.argmax(y_train, axis=1))
best_mod = grid.best_estimator_
y_pred = best_mod.predict(X_test)
y_true = np.argmax(y_test, axis=1)
report = classification_report(y_true, y_pred)
```

### ELECTRA
The code below has been adapted from the following source:

https://www.tensorflow.org/text/tutorials/classify_text_with_bert

```{python}
# code below has been adapted from the following source
https://www.tensorflow.org/text/tutorials/classify_text_with_bert

import tensorflow as tf
import tensorflow_text as text
import numpy as np
import pandas as pd

# Read the uploaded CSV file into a pandas DataFrame
x = pd.read_csv("data.csv")["prompt"]

y = pd.read_csv("y.csv").iloc[:,1:]
# Split dataset into train and a temporary set (70% - 30% split)
x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.3, random_state=42)
x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)

# Assuming you have a list of unique presidents
unique_presidents = y['completion'].unique()

label_map = {name: id for id, name in enumerate(unique_presidents)}
# join dataframes
train = pd.concat([x_train, y_train], axis=1)
val = pd.concat([x_val, y_val], axis=1)
test = pd.concat([x_test, y_test], axis=1)

# Integer-encode labels
train['completion'] = train['completion'].map(label_map)
val['completion'] = val['completion'].map(label_map)
test['completion'] = test['completion'].map(label_map)

# Convert pandas DataFrames to TensorFlow datasets
def pd_to_tf(df, shuffle=True, batch_size=32):
    ds = tf.data.Dataset.from_tensor_slices((df['prompt'].values, df['completion'].values))
    if shuffle:
        ds = ds.shuffle(buffer_size=len(df))
    ds = ds.batch(batch_size)
    ds = ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)
    return ds

train_tf = pd_to_tf(train)
val_tf = pd_to_tf(val, shuffle=False)
test_tf = pd_to_tf(test, shuffle=False)

train_tf = tf.data.Dataset.from_tensor_slices((train['prompt'].values, train['completion'].values))
val_tf = tf.data.Dataset.from_tensor_slices((val['prompt'].values, val['completion'].values))
test_tf = tf.data.Dataset.from_tensor_slices((test['prompt'].values, test['completion'].values))

# Shuffle the train dataset
train_tf = train_tf.shuffle(buffer_size=len(train), seed=42)

# Define batch size; often 32 is used
batch_size = 32

# Batch and cache datasets
train_tf = train_tf.batch(batch_size)
val_tf = val_tf.batch(batch_size)
test_tf = test_tf.batch(batch_size)

# Prefetch data for better performance
train_tf = train_tf.cache().prefetch(buffer_size=tf.data.AUTOTUNE)
val_tf = val_tf.cache().prefetch(buffer_size=tf.data.AUTOTUNE)
test_tf = test_tf.cache().prefetch(buffer_size=tf.data.AUTOTUNE)

tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3' #
tfhub_handle_encoder = 'https://tfhub.dev/google/electra_base/2'

def classifier(num_classes):
  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')
  # electra pre-process
  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')
  encoder_inputs = preprocessing_layer(text_input)
  # electra encoder
  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')
  outputs = encoder(encoder_inputs)
  net = outputs['pooled_output']
  net = tf.keras.layers.Dropout(0.3)(net)
  # Modify this line to adjust the number of output neurons and use softmax
  net = tf.keras.layers.Dense(num_classes, activation='softmax', name='classifier')(net)
  return tf.keras.Model(text_input, net)


num_classes = len(unique_presidents)

with tf.device('/device:GPU:0'):
  classifier_model = classifier(num_classes)
classifier_model.summary()

loss = tf.keras.losses.SparseCategoricalCrossentropy() # beause of imbalanced dataset
metrics = tf.metrics.SparseCategoricalAccuracy()

# only 15 epochs because of how long each epoch takes
epochs = 15
steps_per_epoch = tf.data.experimental.cardinality(train_tf).numpy()
num_train_steps = steps_per_epoch * epochs
num_warmup_steps = int(0.1*num_train_steps)

init_lr = 2e-4
optimizer = optimization.create_optimizer(init_lr=init_lr,num_train_steps=num_train_steps,num_warmup_steps=num_warmup_steps,
                                          optimizer_type='adamw')

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(
    monitor='val_loss',     # show validation loss
    patience=3,             # training halted if 3 epochs go by with no improvement
    restore_best_weights=True  # restore best weights
)

with tf.device('/device:GPU:0'):
  classifier_model.compile(optimizer=optimizer,loss=loss,metrics=metrics)

with tf.device('/device:GPU:0'):
  history = classifier_model.fit(x=train_tf,validation_data=val_tf, epochs=num_epochs, callbacks=[early_stop])

def evaluate_classifier(model, dataset):
    predictions = []
    true_labels = []

    for x, y in dataset:
        predicted_labels = np.argmax(model(x, training=False), axis=1) # choose maximum logit
        true_labels.extend(y.numpy()) # true value
        predictions.extend(predicted_labels) # predicted value

    return true_labels, predictions

test_true, test_pred = evaluate_model(classifier_model, test_tf)
## compute report
class_report = classification_report(test_true, test_pred, target_names=presidents)


```