{
  "hash": "7ab2c26d999f7316ae852753ed8a8581",
  "result": {
    "markdown": "---\ntitle: \"Welcome to all my code\"\nexecute:\n  echo: true\n  eval: false\n---\n\n## Data Cleaning\n\nIn this section, we will perform data cleaning and prepare various datasets for analysis.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport numpy as np\nimport torch\nimport pandas as pd\nimport nltk\nimport re\nfrom nltk.tokenize import sent_tokenize\nnltk.download('punkt')\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n```\n:::\n\n\nExtract names of all data files, store in `files` array, and extract names of all presidents and store in `president_names` array.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nfolder_path = 'data'\nfiles = os.listdir(folder_path)\nfiles = [file for file in files if os.path.isfile(os.path.join(folder_path, file))]\n\nfor file in files[:3]:\n    print(file)\n\npresident_names = []\n\n# Define a regular expression pattern to match the president's name\npattern = r'_(.*?)\\.txt'\n\nfor file in files:\n    match = re.search(pattern, file)\n    if match:\n        president_name = match.group(1)\n        # remove prefix and if not there its fine already\n        president_name = president_name.replace('post_elections_', '').replace('pre_elections_', '')\n        president_names.append(president_name)\n\n```\n:::\n\n\nMake dataset of presidents (column 1) and sentences (column 2).\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndf = pd.DataFrame(columns=['completion', 'prompt'])\n\n# read in file and skip the first two lines\nfor file_index in range(len(files)):\n\n    file_path = f'data/{files[file_index]}'  \n    with open(file_path, 'r', encoding='utf-8') as file:\n        lines = file.readlines()[2:]\n\n    # Combine the lines into a single text\n    text = ' '.join(lines)\n\n    # tokenize the text into sentences using NLTK\n    sentences = sent_tokenize(text) # remove \"\\n\" \n    # remove \"\\n\"\n    cleaned_sentences = [sentence.replace('\\n', '') for sentence in sentences]\n\n    current_president = president_names[file_index]\n    dftemp = pd.DataFrame({'completion': current_president,  'prompt': cleaned_sentences})\n    df = pd.concat([df,dftemp], axis=0)\n\n# remove stopwords function\ndef remove_stopwords(sentence):\n    words = sentence.split()\n    filtered_words = [word for word in words if word.lower() not in ENGLISH_STOP_WORDS]\n    return \" \".join(filtered_words)\n\ndf['prompt'] = df['prompt'].apply(remove_stopwords)\n\ndf.reset_index(drop=True, inplace=True)\n\ndf.to_csv(\"data.csv\")\n```\n:::\n\n\n### Bag of Words \n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nimport pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndef bow_x():\n    # Read the data once\n    data = pd.read_csv(\"data.csv\")\n    \n    # Extract relevant columns\n    text_data = data['prompt']\n    y = data['completion']\n    \n    # Initialize a CountVectorizer for BOW representation\n    vectorizer = CountVectorizer(lowercase=True, token_pattern=r\"(?u)\\b\\w+\\b\")\n    \n    # Fit and transform the text data\n    X = vectorizer.fit_transform(text_data)\n    \n    # Create a DataFrame from the BOW representation\n    bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n    \n    return bow_df\n\n# function to return names of presidents\ndef bow_y():\n  data = pd.read_csv(\"data.csv\")\n  y = data['completion']\n  return(y)\n```\n:::\n\n\n### Term Frequency - Inverse Document Frequency\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# Imports\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n```\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndef idf():\n    df = pd.read_csv(\"data.csv\").iloc[:,1:]\n    sentences = df['prompt'].tolist()\n\n    # Create a TfidfVectorizer\n    tfidf_vectorizer = TfidfVectorizer()\n\n    # Fit and transform the sentences to compute TF-IDF values\n    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n\n    # Create a new dataframe with TF-IDF values\n    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n    return tfidf_df\n```\n:::\n\n\n## Word Embedding\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\ndef embeddings_data_prep():\n    data = pd.read_csv(\"data.csv\").iloc[:, 1:]\n\n    # Tokenization\n    max_features = 1000\n    tokenizer = Tokenizer(num_words=max_features)\n    tokenizer.fit_on_texts(data['prompt'])\n    sequences = tokenizer.texts_to_sequences(data['prompt'])\n\n    # Filter out empty sequences and corresponding labels\n    filtered_indices = [i for i, s in enumerate(sequences) if len(s) > 0]\n    sequences = [sequences[i] for i in filtered_indices]\n    y = data['completion'].iloc[filtered_indices].values\n\n    # Splitting data into training, validation, and test sets\n    x_train, x_temp, y_train, y_temp = train_test_split(sequences, y, test_size=0.3, random_state=42)\n    x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n\n    maxlen = 50\n    x_train_pad = pad_sequences(x_train, maxlen=maxlen)\n    x_val_pad = pad_sequences(x_val, maxlen=maxlen)\n    x_test_pad = pad_sequences(x_test, maxlen=maxlen)\n\n    return x_train_pad, x_val_pad, x_test_pad, y_train, y_val, y_test\n\n\n#x_train_pad, x_val_pad, x_test_pad, y_train, y_val, y_test = embeddings_data_prep()\n```\n:::\n\n\n## Exploratory Data Analysis\n\nNumber of sentences per president.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n\ndata = pd.read_csv(\"data.csv\").iloc[:,1:]\nsentence_counts = data['completion'].value_counts()\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x=sentence_counts.index, y=sentence_counts.values)\n\nplt.xlabel('Presidents')\nplt.ylabel('Number of Sentences')\nplt.savefig('eda_plots/sentence_counts.png', bbox_inches='tight')\nplt.show()\n```\n:::\n\n\nSentence length plot.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ndata['sentence_length'] = data['prompt'].apply(lambda x: len(x.split()))\naverage_sentence_length = data.groupby('completion')['sentence_length'].mean().reset_index()\ndesired_order = [4, 2, 3, 1, 0, 5]\naverage_sentence_length = average_sentence_length.loc[desired_order]\n# Plot the barplot of average sentence lengths per president\nplt.figure(figsize=(10, 6))\nsns.barplot(x='completion', y='sentence_length', data=average_sentence_length)\nplt.xlabel('Presidents')\nplt.ylabel('Average Sentence Length')\nplt.savefig('eda_plots/sentence_length.png', bbox_inches='tight')\nplt.show()\n```\n:::\n\n\nProduce word cloud.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\npresidents = data['completion'].unique()\nfor president in presidents:\n    text = \" \".join(data[data['completion'] == president]['prompt'])\n    \n    # Create a WordCloud object\n    wordcloud = WordCloud(width=800, height=400, background_color='grey').generate(text)\n    \n    # Plot the word cloud\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    #plt.title(f'Word Cloud for President {president}')\n    plt.axis('off')\n    plt.show()\n```\n:::\n\n\n## Models\n\n### Neural Network\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\n# Import required libraries\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport sklearn\nimport pickle\n#from bow import bow_x, bow_y\n\n# Import necessary modules\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# Keras specific\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import to_categorical \nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.regularizers import l2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nx = bow_x()\ny = bow_y()\ndef data_prep(x,y):\n    X_train, X_temp, y_train, y_temp = train_test_split(x, y, test_size=0.3, random_state=42)\n    # Split your data into training and validation sets\n    X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n    X_train = X_train.values\n    X_val = X_val.values\n    X_test = X_test.values\n\n    label_encoder = LabelEncoder()\n\n    # Fit and transform the labels to integer labels\n    y_train_encoded = label_encoder.fit_transform(y_train)\n    y_val_encoded = label_encoder.fit_transform(y_val)\n    y_test_encoded = label_encoder.fit_transform(y_test)\n\n    # Convert to one-hot encoded vector\n    y_train = to_categorical(y_train_encoded)\n    y_val = to_categorical(y_val_encoded)\n    y_test = to_categorical(y_test_encoded)\n\n    # dimensions\n    inp_dim = X_test.shape[1]\n    count_classes = y_test.shape[1]\n    return {\n        'X_train': X_train,\n        'X_val': X_val,\n        'X_test': X_test,\n        'y_train': y_train,\n        'y_val': y_val,\n        'y_test': y_test,\n        'inp_dim': inp_dim,\n        'count_classes': count_classes\n    }\ndata = data_prep(x,y)\nX_train = data['X_train']\nX_val = data['X_val']\nX_test = data['X_test']\ny_train = data['y_train']\ny_val = data['y_val']\ny_test= data['y_test']\ninp_dim = data['inp_dim']\ncount_classes = data['count_classes']\nnum_epochs = 20\n\n# function to train and test model with specific params\ndef create_custom_model(neurons_per_layer, l2_reg_value):\n    # Create a Sequential model\n    model = Sequential()\n    neurons_per_layer = [500, 200]\n    # Add the input layer with L2 regularization\n    model.add(Dense(neurons_per_layer[0], activation='relu', input_dim=inp_dim, kernel_regularizer=l2(l2_reg_value)))\n\n    # Add hidden layers with L2 regularization\n    for num_neurons in neurons_per_layer[1:]:\n        model.add(Dense(num_neurons, activation='relu', kernel_regularizer=l2(l2_reg_value)))\n\n    # Add the output layer with L2 regularization\n    model.add(Dense(count_classes, activation='softmax', kernel_regularizer=l2(l2_reg_value)))\n\n    # Compile the model\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n    # Train the model with validation data\n    history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_val, y_val))\n\n    # Evaluate the model on training and test data\n    scores_train = model.evaluate(X_train, y_train, verbose=1)\n    scores_test = model.evaluate(X_test, y_test, verbose=0)\n    \n\n    # print('Accuracy on training data: {:.2f}%\\nError on training data: {:.2f}'.format(scores_train[1] * 100, (1 - scores_train[1]) * 100))\n    # print('Accuracy on test data: {:.2f}%\\nError on test data: {:.2f}'.format(scores_test[1] * 100, (1 - scores_test[1]) * 100))\n\n    # Access validation scores from the history object\n    val_loss = history.history['val_loss']\n    val_accuracy = history.history['val_accuracy']\n\n    y_pred = model.predict(X_test)\n    y_pred_classes = np.argmax(y_pred, axis=1)  # Convert one-hot encoded predictions to class labels\n\n    # Convert one-hot encoded ground truth labels to class labels\n    y_true_classes = np.argmax(y_test, axis=1)\n\n    # Calculate accuracy, precision, recall, and F1 score\n    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n    precision = precision_score(y_true_classes, y_pred_classes, average=None)\n    recall = recall_score(y_true_classes, y_pred_classes, average=None)\n    f1 = f1_score(y_true_classes, y_pred_classes,\n     average=None)\n\n    # print('Accuracy on test data: {:.2f}%'.format(accuracy * 100))\n    # print('Precision on test data: {:.2f}'.format(precision))\n    # print('Recall on test data: {:.2f}'.format(recall))\n    # print('F1 score on test data: {:.2f}'.format(f1))\n\n    return {\n        'val_loss': val_loss,\n        'val_accuracy': val_accuracy,\n        'train_loss': history.history['loss'],\n        'train_accuracy': history.history['accuracy'],\n        'test_loss': scores_test[0],\n        'test_accuracy': scores_test[1],\n        'precision': precision,\n        'recall': recall,\n        'f1_score': f1\n        }\n```\n:::\n\n\nCreate 3 model architectures, and implement L2 regularization on best performing one. First with BoW data.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nbow_results_2 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0)\nbow_results_3 = create_custom_model(neurons_per_layer=[500,200,100], l2_reg_value=0)\nbow_results_4 = create_custom_model(neurons_per_layer=[800,400,100,50], l2_reg_value=0)\n\n# bow_results_2[\"test_accuracy\"] #0.5952890515327454\n# bow_results_3[\"test_accuracy\"] #0.5852962136268616\n# bow_results_4[\"test_accuracy\"] #0.6038544178009033\n```\n:::\n\n\nNow regularize the 2 layer Neural Network, since the benefit is incremental, but much less compute needed.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nbow_results_2_001 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0.01)\n\nbow_results_2_005 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0.05)\n\nbow_results_2_01 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0.1)\n\nbow_results_2_001[\"test_accuracy\"] #0.5952890515327454\nbow_results_2_005[\"test_accuracy\"] #0.5852962136268616\nbow_results_2_01[\"test_accuracy\"] #0.6038544178009033\n\nbow_results_2_0 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0)\n```\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nfile_path = 'nn_res/bow_results_2_0.pkl'\nwith open(file_path, 'wb') as file:\n    pickle.dump(bow_results_2_0, file)\n```\n:::\n\n\nNow do the same process but for TF-IDF dataset.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n#from tf_idf import idf\n# import idf data\nx = idf()\ndata = data_prep(x,y)\nX_train = data['X_train']\nX_val = data['X_val']\nX_test = data['X_test']\ny_train = data['y_train']\ny_val = data['y_val']\ny_test= data['y_test']\ninp_dim = data['inp_dim']\ncount_classes = data['count_classes']\n\nidf_results_2 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0)\nidf_results_3 = create_custom_model(neurons_per_layer=[500,200,100], l2_reg_value=0)\nidf_results_4 = create_custom_model(neurons_per_layer=[800,400,100,50], l2_reg_value=0)\n\nidf_results_2[\"test_accuracy\"] #0.600285530090332\nidf_results_3[\"test_accuracy\"] #0.599571704864502\nidf_results_4[\"test_accuracy\"] #0.5888651013374329\n\n\nidf_results_2_001 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0.01)\n\nidf_results_2_005 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0.05)\n\nidf_results_2_01 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0.1)\n\n# no reg is the best\nidf_results_2_0 = create_custom_model(neurons_per_layer=[500,200], l2_reg_value=0)\n\n\n# idf_results_2_001[\"test_accuracy\"] #0.600285530090332\n# idf_results_2_005[\"test_accuracy\"] #0.599571704864502\n# idf_results_2_01[\"test_accuracy\"] #0.5888651013374329\nidf_results_2_0[\"test_accuracy\"]\n\nfile_path = 'nn_res/idf_results_2_0.pkl'\nwith open(file_path, 'wb') as file:\n    pickle.dump(idf_results_2_0, file)\n```\n:::\n\n\nAnd train networks for word embeddings.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\n#from embedding import embeddings_data_prep\n\nX_train, X_val, X_test, y_train, y_val, y_test = embeddings_data_prep()\n# encode the y values\nlabel_encoder = LabelEncoder()\n\n# Fit and transform the labels to integer labels\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_val_encoded = label_encoder.fit_transform(y_val)\ny_test_encoded = label_encoder.fit_transform(y_test)\n\n# Convert to one-hot encoded vector\ny_train = to_categorical(y_train_encoded)\ny_val = to_categorical(y_val_encoded)\ny_test = to_categorical(y_test_encoded)\n\n# dimensions\ninp_dim = X_test.shape[1]\ncount_classes = y_test.shape[1]\n```\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n# train models\nnum_epochs = 100\nembeds_results_2 = create_custom_model(neurons_per_layer=[40,10], l2_reg_value=0)\nembeds_results_3 = create_custom_model(neurons_per_layer=[40,30,10], l2_reg_value=0)\nembeds_results_4 = create_custom_model(neurons_per_layer=[40,30,20,10], l2_reg_value=0)\n\nembeds_results_2[\"test_accuracy\"] #0.2942446172237396\nembeds_results_3[\"test_accuracy\"] #0.2942446172237396\nembeds_results_4[\"test_accuracy\"] #0.3179856240749359\n\n# now with reg\n\nembeds_results_2_001 = create_custom_model(neurons_per_layer=[40,30,20,10], l2_reg_value=0.01)\n\nembeds_results_2_005 = create_custom_model(neurons_per_layer=[40,30,20,10], l2_reg_value=0.05)\n\nembeds_results_2_01 = create_custom_model(neurons_per_layer=[40,30,20,10], l2_reg_value=0.1)\n\n\nembeds_results_2_001[\"test_accuracy\"] #0.600285530090332\nembeds_results_2_005[\"test_accuracy\"] #0.599571704864502\nembeds_results_2_01[\"test_accuracy\"] #0.5888651013374329\nnum_epochs = 200\nembeds_results_2_0 = create_custom_model(neurons_per_layer=[40,30,20,10], l2_reg_value=0)\n\n\nfile_path = 'nn_res/embed_results_2_0.pkl'\nwith open(file_path, 'wb') as file:\n    pickle.dump(embeds_results_2_0, file)\n```\n:::\n\n\nPLOT MODEL INFORMATION.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nwith open(\"nn_res/bow_results_2_0.pkl\", 'rb') as file:\n    bow_res = pickle.load(file)\n\nwith open(\"nn_res/idf_results_2_0.pkl\", 'rb') as file:\n    idf_res = pickle.load(file)\n\nwith open(\"nn_res/embed_results_2_0.pkl\", 'rb') as file:\n    embed_res = pickle.load(file)\n\nbow_val = bow_res[\"val_accuracy\"]\nidf_val = idf_res[\"val_accuracy\"]\nembed_val = embed_res[\"val_accuracy\"][::10]\nx_bow = range(len(bow_val))\nx_idf = range(len(idf_val))\nx_embed = range(len(embed_val))\nx_ticks = list(range(20))\n\nfig, ax = plt.subplots()\nax.plot(x_bow, bow_val, label='BoW')#, marker='o')\nax.plot(x_idf, idf_val, label='IDF')#, marker='s')\nax.plot(x_embed, embed_val, label='Embeddings')#, marker='^')\n\n# Set labels and title\nax.set_xlabel('Epochs')\nax.set_ylabel('Validation Accuracy')\nax.set_title('Validation Accuracy Comparison')\nax.legend()\nax.set_xticks(range(21))\nplt.grid(True)\nplt.savefig('nn_res/nn_val_acc.png', bbox_inches='tight')\nplt.show()\n```\n:::\n\n\n### Boosted Tree\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nimport catboost as cb\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport shap\nimport re\nimport pickle\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom catboost import CatBoostClassifier\nimport collections\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n# from bow import bow_x, bow_y\n# from tf_idf import idf\n# from embedding import embeddings_data_prep\n```\n:::\n\n\nFirst we do catboost on BoW data.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\n# SPLIT INTO BAG OF WORDS FORMAT\nx = bow_x()\ny = bow_y()\n# split data train,val,test\n# Split the data into training (70%), validation (15%), and test (15%) sets\nx_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.3, random_state=42)\n\nx_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n\n# BRING DATA: SPLIT INTO TRAIN, VALIDATION AND TEST\ntrain_dataset = cb.Pool(x_train, y_train) \nval_dataset = cb.Pool(x_val, y_val) \ntest_dataset = cb.Pool(x_test, y_test)\n# CREATE CATBOOST MODEL\ncatboost_classifier = CatBoostClassifier()\n#CREATE GRID OF PARAMETERS\ngrid = {'iterations': [10, 50, 80],\n        'learning_rate': [0.03, 0.05],\n        'depth': [4, 5, 6],\n        'l2_leaf_reg': [0.2, 0.5]}\n# Define the parameter grid\ngrid_search = GridSearchCV(estimator=catboost_classifier, param_grid=grid, cv=3, n_jobs=-1)\n\n# Fit the grid search to your data\ngrid_search.fit(x_train, y_train)  # Replace X and y with your feature and label data\n# Get the best parameters and estimator\n# best: {'depth': 6, 'iterations': 80, 'l2_leaf_reg': 0.2, 'learning_rate': 0.05}\nbest_params = grid_search.best_params_\nbest_params['iterations'] = 4000\n# best_estimator = grid_search.best_estimator_\n# y_pred = best_estimator.predict(x_test)\nclf = CatBoostClassifier(**best_params)\nclf.fit(train_dataset, eval_set=val_dataset, plot=True)\nbow_val_acc = clf.eval_metrics(val_dataset, metrics=[\"Accuracy\"])\n\n# Calculate accuracy\ny_pred = clf.predict(test_dataset)\naccuracy = accuracy_score(y_test, y_pred)\n\n# Calculate precision\nprecision = precision_score(y_test, y_pred, average=None)\nrecall = recall_score(y_test, y_pred, average=None)\nf1 = f1_score(y_test, y_pred, average=None)\nconfusion = confusion_matrix(y_test, y_pred)\n\nperformance_metrics = {\n    \"val_accuracy\": bow_val_acc,\n    \"accuracy\": accuracy,\n    \"precision\": precision,\n    \"recall\": recall,\n    \"f1\": f1,\n    \"confusion_matrix\": confusion\n}\n# save val acc\nfile_path = 'catboost_info/bow_res.pkl'\nwith open(file_path, 'wb') as file:\n    pickle.dump(performance_metrics, file)\n\n```\n:::\n\n\nNow run catboost on IDF data.\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nx = idf()\ny = pd.read_csv(\"y.csv\").iloc[:,1:]\n# split data train,val,test\n# Split the data into training (70%), validation (15%), and test (15%) sets\nx_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.3, random_state=42)\n\nx_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n\n# BRING DATA: SPLIT INTO TRAIN, VALIDATION AND TEST\ntrain_dataset = cb.Pool(x_train, y_train) \nval_dataset = cb.Pool(x_val, y_val) \ntest_dataset = cb.Pool(x_test, y_test)\n# CREATE CATBOOST MODEL\ncatboost_classifier = CatBoostClassifier()\n# CREATE GRID OF PARAMETERS\ngrid = {'iterations': [80],\n        'learning_rate': [0.03, 0.05],\n        'depth': [4, 5, 6],\n        'l2_leaf_reg': [0.2, 0.5]}\n# Define the parameter grid\ngrid_search = GridSearchCV(estimator=catboost_classifier, param_grid=grid, cv=3, n_jobs=-1)\n# Fit the grid search to your data\ngrid_search.fit(x_train, y_train)  # Replace X and y with your feature and label data\n\n# Get the best parameters and estimator\nbest_params = grid_search.best_params_\nbest_params['iterations'] = 4000\n# best_estimator = grid_search.best_estimator_\n# y_pred = best_estimator.predict(x_test)\nclf = CatBoostClassifier(**best_params)\nclf.fit(train_dataset, eval_set=val_dataset, plot=True)\nidf_val_acc = clf.eval_metrics(val_dataset, metrics=[\"Accuracy\"])\n\n# Calculate accuracy\ny_pred = clf.predict(test_dataset)\naccuracy = accuracy_score(y_test, y_pred)\n\n# Calculate precision\nprecision = precision_score(y_test, y_pred, average=None)\nrecall = recall_score(y_test, y_pred, average=None)\nf1 = f1_score(y_test, y_pred, average=None)\nconfusion = confusion_matrix(y_test, y_pred)\n\nperformance_metrics = {\n    \"val_accuracy\": idf_val_acc,\n    \"accuracy\": accuracy,\n    \"precision\": precision,\n    \"recall\": recall,\n    \"f1\": f1,\n    \"confusion_matrix\": confusion\n}\n# save val acc\nfile_path = 'catboost_info/idf_res.pkl'\nwith open(file_path, 'wb') as file:\n    pickle.dump(performance_metrics, file)\n```\n:::\n\n\nNow we do catboost on word embeddings.\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\n# split data train,val,test\nx_train, x_val, x_test, y_train, y_val, y_test = embeddings_data_prep()\n\n# BRING DATA: SPLIT INTO TRAIN, VALIDATION AND TEST\ntrain_dataset = cb.Pool(x_train, y_train) \nval_dataset = cb.Pool(x_val, y_val) \ntest_dataset = cb.Pool(x_test, y_test)\n# CREATE CATBOOST MODEL\ncatboost_classifier = CatBoostClassifier()\n# CREATE GRID OF PARAMETERS\ngrid = {'iterations': [80],\n        'learning_rate': [0.03, 0.05],\n        'depth': [4, 5, 6],\n        'l2_leaf_reg': [0.2, 0.5]}\n# Define the parameter grid\ngrid_search = GridSearchCV(estimator=catboost_classifier, param_grid=grid, cv=3, n_jobs=-1)\n# Fit the grid search to your data\ngrid_search.fit(x_train, y_train)  # Replace X and y with your feature and label data\n\n#Get the best parameters and estimator\nbest_params = grid_search.best_params_\nbest_params['iterations'] = 4000\n# best_estimator = grid_search.best_estimator_\n# y_pred = best_estimator.predict(x_test)\nclf = CatBoostClassifier(**best_params)\nclf.fit(train_dataset, eval_set=val_dataset, plot=True)\nembed_val_acc = clf.eval_metrics(val_dataset, metrics=[\"Accuracy\"])\n\n# Calculate accuracy\ny_pred = clf.predict(test_dataset)\naccuracy = accuracy_score(y_test, y_pred)\n\n# Calculate precision\nprecision = precision_score(y_test, y_pred, average=None)\nrecall = recall_score(y_test, y_pred, average=None)\nf1 = f1_score(y_test, y_pred, average=None)\nconfusion = confusion_matrix(y_test, y_pred)\n\nperformance_metrics = {\n    \"val_accuracy\": embed_val_acc,\n    \"accuracy\": accuracy,\n    \"precision\": precision,\n    \"recall\": recall,\n    \"f1\": f1,\n    \"confusion_matrix\": confusion\n}\n# save val acc\nfile_path = 'catboost_info/embed_res.pkl'\nwith open(file_path, 'wb') as file:\n    pickle.dump(performance_metrics, file)\n```\n:::\n\n\nPlot validation accuracy.\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nwith open('catboost_info/bow_res.pkl', 'rb') as file:\n    cbbow_res = pickle.load(file)\n\nwith open('catboost_info/idf_res.pkl', 'rb') as file:\n    cbidf_res = pickle.load(file)\n\nwith open('catboost_info/embed_res.pkl', 'rb') as file:\n    cbembed_res = pickle.load(file)\n\n\ncbbow_val = bow_res[\"val_accuracy\"][\"Accuracy\"]\ncbidf_val = idf_res[\"val_accuracy\"][\"Accuracy\"]\ncbembed_val = embed_res[\"val_accuracy\"][\"Accuracy\"]\ncb_bow = range(4000)\ncb_idf = range(3995)\ncb_embed = range(130)\n\n\nfig, ax = plt.subplots()\n\n# Plot the validation values for each experiment\nax.plot(cb_bow, cbbow_val, label='BoW')#, marker='o')\nax.plot(cb_idf, cbidf_val, label='IDF')#, marker='s')\nax.plot(cb_embed, cbembed_val, label='Embeddings')#, marker='^')\n\n# Set labels and title\nax.set_xlabel('Epochs')\nax.set_ylabel('Validation Accuracy')\n#ax.set_title('Validation Accuracy Comparison')\nax.legend()\nplt.grid(True)\nplt.savefig('catboost_info/cb_val_acc.png')#, bbox_inches='tight')\nplt.show()\n```\n:::\n\n\n### Naive Bayes\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nimport numpy as np\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical \nimport numpy as np\nimport pandas as pd\n# from bow import bow_x, bow_y\n# from tf_idf import idf\n# from embedding import embeddings_data_prep\n```\n:::\n\n\nNB model for BoW data first.\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\nx = bow_x()\ny = bow_y()\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n# Split your data into training and validation sets\nX_train = X_train.values\nX_test = X_test.values\n\nlabel_encoder = LabelEncoder()\n\n# Fit and transform the labels to integer labels\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.fit_transform(y_test)\n\n# Convert to one-hot encoded vector\ny_train = to_categorical(y_train_encoded)\ny_test = to_categorical(y_test_encoded)\n```\n:::\n\n\nMake a function to train NB model on custom data.\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\ndef naive_bayes(X_train, y_train, X_test, y_test):\n    # Define a grid of hyperparameter values to search through\n    param_grid = {'alpha': [0.001, 0.01, 0.1, 1.0]}\n    # Create a Multinomial Naive Bayes classifier\n    nb_classifier = MultinomialNB()\n    # Perform a grid search to find the best hyperparameter ('alpha')\n    grid_search = GridSearchCV(nb_classifier, param_grid, cv=5, scoring='accuracy')\n    # Fit the grid search to the training data\n    grid_search.fit(X_train, np.argmax(y_train, axis=1))\n    # Get the best Naive Bayes classifier based on the grid search results\n    best_nb_classifier = grid_search.best_estimator_\n    # Make predictions on the test set using the best classifier\n    y_pred_nb = best_nb_classifier.predict(X_test)\n    # Extract the true labels from one-hot encoded 'y_test'\n    y_true = np.argmax(y_test, axis=1)\n    # Calculate the accuracy of the classifier on the test set\n    accuracy = accuracy_score(y_true, y_pred_nb)\n    # Store the results including accuracy, best alpha, and the best classifier\n    results = {\n        'accuracy': accuracy,\n        'best_alpha': grid_search.best_params_['alpha'],\n        'fitted_model': best_nb_classifier\n    }\n    # Create a DataFrame to store results for reporting\n    results_df = pd.DataFrame([{\n        'best_alpha': results['best_alpha'],\n        'train_accuracy': accuracy_score(np.argmax(y_train, axis=1), best_nb_classifier.predict(X_train)),\n        'test_accuracy': accuracy\n    }])\n    \n    # Return the results, results DataFrame, and the best classifier\n    return results, results_df, best_nb_classifier\n\nopt = naive_bayes(X_test=X_test,X_train=X_train,y_test=y_test, y_train=y_train)\n\n# train the best model and output\nmod = MultinomialNB()\nparam = {'alpha': [1.0]}\ngrid = GridSearchCV(mod, param, cv=5, scoring='accuracy')\ngrid.fit(X_train, np.argmax(y_train, axis=1))\nbest_mod = grid.best_estimator_\ny_pred = best_mod.predict(X_test)\ny_true = np.argmax(y_test, axis=1)\nreport = classification_report(y_true, y_pred)\n\n```\n:::\n\n\nNow do it for TF-IDF data.\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\nx = idf()\ny = bow_y()\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n# Split your data into training and validation sets\nX_train = X_train.values\nX_test = X_test.values\n\nlabel_encoder = LabelEncoder()\n\n# Fit and transform the labels to integer labels\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.fit_transform(y_test)\n\n# Convert to one-hot encoded vector\ny_train = to_categorical(y_train_encoded)\ny_test = to_categorical(y_test_encoded)\n\nopt = naive_bayes(X_test=X_test,X_train=X_train,y_test=y_test, y_train=y_train)\n\n# train the best model and output\nmod = MultinomialNB()\nparam = {'alpha': [0.1]}\ngrid = GridSearchCV(mod, param, cv=5, scoring='accuracy')\ngrid.fit(X_train, np.argmax(y_train, axis=1))\nbest_mod = grid.best_estimator_\ny_pred = best_mod.predict(X_test)\ny_true = np.argmax(y_test, axis=1)\nreport = classification_report(y_true, y_pred)\n```\n:::\n\n\nNow train the NB model with embeddings.\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\nX_train, X_val, X_test, y_train, y_val, y_test = embeddings_data_prep()\n\nX_test = np.concatenate((X_val, X_test), axis=0)\ny_test = np.concatenate((y_val, y_test), axis=0)\n\n# encode the y values\nlabel_encoder = LabelEncoder()\n\n# Fit and transform the labels to integer labels\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.fit_transform(y_test)\n\n# Convert to one-hot encoded vector\ny_train = to_categorical(y_train_encoded)\ny_test = to_categorical(y_test_encoded)\n\nopt = naive_bayes(X_test=X_test,X_train=X_train,y_test=y_test, y_train=y_train)\n\n# train the best model and output\nmod = MultinomialNB()\nparam = {'alpha': [10]}\ngrid = GridSearchCV(mod, param, cv=5, scoring='accuracy')\ngrid.fit(X_train, np.argmax(y_train, axis=1))\nbest_mod = grid.best_estimator_\ny_pred = best_mod.predict(X_test)\ny_true = np.argmax(y_test, axis=1)\nreport = classification_report(y_true, y_pred)\n```\n:::\n\n\n",
    "supporting": [
      "allcode_files"
    ],
    "filters": [],
    "includes": {}
  }
}